{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":98505,"databundleVersionId":11755333,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom datetime import datetime\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as n\n\n\n# Convert size strings like '10M', '500K' to float in MB\ndef convert_size(value):\n    if pd.isna(value):\n        return pd.NA\n    value = str(value)\n    if 'M' in value:\n        return float(value.replace('M', ''))\n    elif 'K' in value or 'k' in value:\n        return float(value.replace('K', '').replace('k', '')) / 1024\n    return pd.NA\n    \ndef parse_date(value):\n    try:\n        # Convert to datetime, handling common date formats\n        return pd.to_datetime(value, errors='coerce', format='%B %d, %Y')\n    except Exception as e:\n        return pd.NaT  # Return Not a Time for invalid dates\n\n# Extract float version from a string like '4.1 and up'\ndef preprocess_X11(value):\n    if pd.isna(value) or 'Varies' in str(value):\n        return pd.NA\n    try:\n        return float(str(value).split()[0])\n    except ValueError:\n        return pd.NA\n        \ndef label(value, label_mapping={}):\n    if value not in label_mapping:\n        label_mapping[value] = len(label_mapping)  # Assign the next integer\n    return label_mapping[value]\n        \ndef preprocess_train_data(train_path):\n    df = pd.read_csv(train_path)\n    df_clean = df.copy()\n    df_clean = df_clean[['X3','X4','X5','X9','X11','Y']] \n    \n    #df_clean['Y'] = df_clean['Y'].fillna(df_clean['Y'].median())\n    df_clean = df_clean.dropna(subset=['Y'])\n    df_clean = df_clean[(df_clean['Y'] >= 1) & (df_clean['Y'] <= 5)]\n    \n    # Preprocess X1 (Categories)\n    # label_mappingX1 = {}\n    # df_clean['X1'] = df_clean['X1'].apply(lambda x: label(x, label_mappingX1))\n    \n    # Preprocess X2 (Reviews)\n    # df_clean['X2'] = df_clean['X2'].astype(str).str.replace(',', '', regex=False)\n    # df_clean['X2'] = pd.to_numeric(df_clean['X2'], errors='coerce')\n\n    # Process X3 (Size)\n    df_clean['X3'] = df_clean['X3'].replace('Varies with device', pd.NA)\n    df_clean['X3'] = df_clean['X3'].apply(convert_size)\n    df_clean['X3'] = pd.to_numeric(df_clean['X3'], errors='coerce')\n\n    # Process X4 (Downloads)\n    df_clean['X4'] = df_clean['X4'].apply(lambda x: x.strip('+').replace(',', ''))\n    df_clean['X4'] = pd.to_numeric(df_clean['X4'], errors='coerce')\n\n\n    # Process X5 (Type: Free=0, Paid=1)\n    df_clean['X5'] = df_clean['X5'].map({'Free': 0, 'Paid': 1})\n\n    # # Preprocess X7 (Age groups)\n    # label_mappingX7 = {}\n    # df_clean['X7'] = df_clean['X7'].apply(lambda x: label(x, label_mappingX7))\n\n    \n    # Preprocess X9 (Date)\n    df_clean['X9'] = df_clean['X9'].apply(parse_date)\n    today_date = datetime(2025, 5, 9)\n    # Calculate the number of days since today (09/05/2025)\n    df_clean['X9'] = (today_date - df_clean['X9']).dt.days\n\n    \n    # Process X11 (Android Version)\n    df_clean['X11'] = df_clean['X11'].apply(preprocess_X11)\n    df_clean['X11'] = pd.to_numeric(df_clean['X11'], errors='coerce')\n\n     # === Impute X3 using Linear Regression on ['X1','X5','X7','X9'] ===\n    mask_x3 = df_clean['X3'].isna()\n    if mask_x3.any():\n        lr_x3 = LinearRegression()\n        known = ~mask_x3\n        lr_x3.fit(df_clean.loc[known, ['X4','X5','X9']],\n                  df_clean.loc[known, 'X3'])\n        df_clean.loc[mask_x3, 'X3'] = lr_x3.predict(df_clean.loc[mask_x3, ['X4','X5','X9']])\n\n    \n    # === Impute X11 using Linear Regression on ['X1','X3','X5','X7','X9'] ===\n    mask_x11 = df_clean['X11'].isna()\n    if mask_x11.any():\n        lr_x11 = LinearRegression()\n        known11 = ~mask_x11\n        lr_x11.fit(df_clean.loc[known11, ['X4','X3','X5','X9']],\n                   df_clean.loc[known11, 'X11'])\n        df_clean.loc[mask_x11, 'X11'] = lr_x11.predict(df_clean.loc[mask_x11, ['X4','X3','X5','X9']])\n\n    return df_clean, (lr_x3, lr_x11) ,df_clean.columns.drop('Y').tolist()\n\n\n# Preprocess test data\ndef preprocess_test_data(test_path, lr_models, feature_columns):\n    lr_x3, lr_x11 = lr_models\n    df_test = pd.read_csv(test_path)\n    \n    if 'row_id' in df_test.columns:\n        test_ids = df_test['row_id']\n    elif 'ID' in df_test.columns:\n        test_ids = df_test['ID']\n    else:\n        test_ids = df_test.index\n\n    df_clean = df_test[[ 'X3', 'X4', 'X5','X9','X11']].copy()  \n    \n    # Preprocess X1 (Categories)\n    # label_mappingX1 = {}\n    # df_clean['X1'] = df_clean['X1'].apply(lambda x: label(x, label_mappingX1))\n    \n    # Preprocess X2 (Reviews)\n    # df_clean['X2'] = df_clean['X2'].astype(str).str.replace(',', '', regex=False)\n    # df_clean['X2'] = pd.to_numeric(df_clean['X2'], errors='coerce')\n\n    # Process X3 (Size)\n    df_clean['X3'] = df_clean['X3'].replace('Varies with device', pd.NA)\n    df_clean['X3'] = df_clean['X3'].apply(convert_size)\n    df_clean['X3'] = pd.to_numeric(df_clean['X3'], errors='coerce')\n\n    # Process X4 (Downloads)\n    df_clean['X4'] = df_clean['X4'].apply(lambda x: x.strip('+').replace(',', ''))\n    df_clean['X4'] = pd.to_numeric(df_clean['X4'], errors='coerce')\n\n\n    # Process X5 (Type: Free=0, Paid=1)\n    df_clean['X5'] = df_clean['X5'].map({'Free': 0, 'Paid': 1})\n\n    # Preprocess X7 (Age groups)\n    # label_mappingX7 = {}\n    # df_clean['X7'] = df_clean['X7'].apply(lambda x: label(x, label_mappingX7))\n\n    \n    # Preprocess X9 (Date)\n    df_clean['X9'] = df_clean['X9'].apply(parse_date)\n    today_date = datetime(2025, 5, 9)\n    # Calculate the number of days since today (09/05/2025)\n    df_clean['X9'] = (today_date - df_clean['X9']).dt.days\n\n    \n    # Process X11 (Android Version)\n    df_clean['X11'] = df_clean['X11'].apply(preprocess_X11)\n    df_clean['X11'] = pd.to_numeric(df_clean['X11'], errors='coerce')\n \n    mask_x3 = df_clean['X3'].isna()\n    if mask_x3.any():\n        # reuse lr_x3 trained on train data\n        df_clean.loc[mask_x3, 'X3'] = lr_x3.predict(df_clean.loc[mask_x3, ['X4','X5','X9']])\n    \n    # Impute X11\n    mask_x11 = df_clean['X11'].isna()\n    if mask_x11.any():\n        df_clean.loc[mask_x11, 'X11'] = lr_x11.predict(df_clean.loc[mask_x11, ['X4','X3','X5','X9']])\n    \n   \n    for col in feature_columns:\n        if col not in df_clean.columns:\n            df_clean[col] = 0\n    df_clean = df_clean[feature_columns]\n\n    return df_clean, test_ids\n\ndef train_on_full_data(X, y, k=5):\n    # Initialize k-fold\n    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n    \n    r2_scores = []\n    mae_scores = []\n    rmse_scores = []\n\n    for fold, (train_index, test_index) in enumerate(kf.split(X)):\n        print(f\"\\nFold {fold + 1}/{k}\")\n        \n        # Split the data into train and test sets\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        \n        # Scale the features\n        scaler = StandardScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_test_scaled = scaler.transform(X_test)\n        \n        # Train the model\n        model = RandomForestRegressor(n_estimators=200, random_state=42, min_samples_leaf=10,max_features=3,max_depth=6)\n        model.fit(X_train_scaled, y_train)\n        predictions = model.predict(X_test_scaled)\n        \n        # Evaluate the model\n        r2 = r2_score(y_test, predictions)\n        mae = mean_absolute_error(y_test, predictions)\n        rmse = mean_squared_error(y_test, predictions, squared=False)\n        \n        print(f\"R²: {r2:.4f}, MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n        \n        # Store the scores\n        r2_scores.append(r2)\n        mae_scores.append(mae)\n        rmse_scores.append(rmse)\n    \n    # Print the average scores\n    print(\"\\nOverall Performance Across Folds:\")\n    print(f\"Mean R²: {np.mean(r2_scores):.4f}\")\n    print(f\"Mean MAE: {np.mean(mae_scores):.4f}\")\n    print(f\"Mean RMSE: {np.mean(rmse_scores):.4f}\")\n    \n    return model, scaler\n\n\n\ndef generate_submission(model, scaler, test_data, test_ids, output_path, sample_submission_path):\n    test_data_scaled = scaler.transform(test_data)\n    predictions = model.predict(test_data_scaled)\n    predictions = predictions.round(2)\n\n    sample_submission = pd.read_csv(sample_submission_path)\n    submission = pd.DataFrame({\n        'row_id': sample_submission['row_id'],\n        'Y': predictions\n    })\n\n    submission.to_csv(output_path, index=False)\n    print(f\"Submission saved to {output_path}\")\n\nif __name__ == \"__main__\":\n    train_path = \"/kaggle/input/app-rating-competition/train.csv\"\n    test_path = \"/kaggle/input/app-rating-competition/test.csv\"\n    sample_submission_path = \"/kaggle/input/app-rating-competition/SampleSubmission.csv\"\n    submission_path = \"/kaggle/working/submission.csv\"\n\n    train_data, (lr_x3, lr_x11), feature_columns = preprocess_train_data(train_path)\n\n    print(\"\\nCorrelation matrix:\")\n    print(train_data.corr()['Y'].sort_values(ascending=False))\n\n    X = train_data.drop('Y', axis=1)\n    y = train_data['Y']\n\n    model, scaler = train_on_full_data(X, y)\n\n    test_data, test_ids = preprocess_test_data(test_path, (lr_x3, lr_x11), feature_columns)\n    generate_submission(model, scaler, test_data, test_ids, submission_path, sample_submission_path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T17:35:27.106601Z","iopub.execute_input":"2025-05-10T17:35:27.106949Z","iopub.status.idle":"2025-05-10T17:35:33.250792Z","shell.execute_reply.started":"2025-05-10T17:35:27.106925Z","shell.execute_reply":"2025-05-10T17:35:33.2498Z"}},"outputs":[],"execution_count":null}]}