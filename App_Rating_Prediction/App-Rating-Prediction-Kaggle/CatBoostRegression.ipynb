{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":98505,"databundleVersionId":11755333,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.tools import add_constant\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import KFold\n\ndef convert_size(value):\n    if pd.isna(value):\n        return pd.NA\n    value = str(value)\n    if 'M' in value:\n        return float(value.replace('M', ''))\n    elif 'K' in value:\n        return float(value.replace('K', '')) / 1024\n    else:\n        return pd.NA\n\ndef preprocess_X11(value):\n    if pd.isna(value) or 'Varies' in str(value):\n        return pd.NA\n    version = str(value).split()[0]\n    try:\n        return float(version)\n    except ValueError:\n        return pd.NA\n\ndef preprocess_train_data(train_path):\n    df = pd.read_csv(train_path)\n    df_clean = df.dropna(subset=['Y']).copy()\n    df_clean = df_clean[['X3', 'X5', 'X11', 'Y']]\n    df_clean = df_clean[(df_clean['Y'] >= 1) & (df_clean['Y'] <= 5)]\n\n    # Convert app size\n    df_clean['X3'] = df_clean['X3'].replace('Varies with device', pd.NA)\n    df_clean['X3'] = df_clean['X3'].apply(lambda x: convert_size(x) if pd.notna(x) else x)\n    df_clean['X3'] = pd.to_numeric(df_clean['X3'], errors='coerce')\n\n    # Convert type\n    df_clean['X5'] = df_clean['X5'].map({'Free': 0, 'Paid': 1})\n\n    # Convert Android version\n    df_clean['X11'] = df_clean['X11'].apply(preprocess_X11)\n    df_clean['X11'] = pd.to_numeric(df_clean['X11'], errors='coerce')\n\n    # Separate imputers for numeric and categorical\n    num_imputer = SimpleImputer(strategy='median')\n    cat_imputer = SimpleImputer(strategy='most_frequent')\n    \n    # Impute numeric features\n    df_clean[['X3', 'X11']] = num_imputer.fit_transform(df_clean[['X3', 'X11']])\n    # Impute categorical feature\n    df_clean['X5'] = cat_imputer.fit_transform(df_clean[['X5']])\n\n    return df_clean, (num_imputer, cat_imputer), df_clean.columns.drop('Y').tolist()\n\ndef preprocess_test_data(test_path, imputers, feature_columns):\n    num_imputer, cat_imputer = imputers\n    df_test = pd.read_csv(test_path)\n\n    test_ids = df_test.get('row_id', df_test.index)\n    \n    df_clean = df_test[['X3', 'X5', 'X11']].copy()\n\n    # Convert app size\n    df_clean['X3'] = df_clean['X3'].replace('Varies with device', pd.NA)\n    df_clean['X3'] = df_clean['X3'].apply(lambda x: convert_size(str(x)) if pd.notna(x) else x)\n    df_clean['X3'] = pd.to_numeric(df_clean['X3'], errors='coerce')\n\n    # Convert type\n    df_clean['X5'] = df_clean['X5'].map({'Free': 0, 'Paid': 1})\n\n    # Convert Android version\n    df_clean['X11'] = df_clean['X11'].apply(preprocess_X11)\n    df_clean['X11'] = pd.to_numeric(df_clean['X11'], errors='coerce')\n\n    # Apply imputers\n    df_clean[['X3', 'X11']] = num_imputer.transform(df_clean[['X3', 'X11']])\n    df_clean['X5'] = cat_imputer.transform(df_clean[['X5']])\n\n    # Ensure feature columns exist\n    for col in feature_columns:\n        if col not in df_clean.columns:\n            df_clean[col] = 0\n\n    df_clean = df_clean[feature_columns]\n    return df_clean, test_ids\n\ndef train_on_full_data(X, y):\n    # Define categorical features\n    cat_features = X.select_dtypes('category').columns.tolist()\n    \n    # Initialize and train CatBoost\n    model = CatBoostRegressor(\n        iterations=500,\n        learning_rate=0.000455,\n        depth=5,\n        cat_features=cat_features,\n        random_seed=42,\n        verbose=0\n    )\n    model.fit(X, y)\n    \n    # Evaluate\n    predictions = model.predict(X)\n    print(\"\\nCatBoost Training Performance:\")\n    print(f\"RÂ²: {r2_score(y, predictions):.4f}\")\n    print(f\"MAE: {mean_absolute_error(y, predictions):.4f}\")\n    print(f\"RMSE: {mean_squared_error(y, predictions, squared=False):.4f}\")\n    \n    return model\n\ndef analyze_features(X, y, model=None):\n    # Feature correlation analysis\n    plt.figure(figsize=(12, 8))\n    corr_matrix = X.join(y).corr()\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n    plt.title(\"Feature Correlation Matrix\")\n    plt.show()\n\n    # CatBoost feature importance\n    if model:\n        importance = model.get_feature_importance()\n        importance_df = pd.DataFrame({\n            'Feature': X.columns,\n            'Importance': importance\n        }).sort_values('Importance', ascending=False)\n        \n        plt.figure(figsize=(10, 6))\n        sns.barplot(x='Importance', y='Feature', data=importance_df)\n        plt.title(\"CatBoost Feature Importance\")\n        plt.show()\n\n    # Partial dependence plots (fixed version)\n    if model:\n        plt.figure(figsize=(15, 10))\n        \n        # Get numerical and categorical features\n        numerical_features = X.select_dtypes(include=np.number).columns\n        categorical_features = X.select_dtypes(exclude=np.number).columns\n        \n        for i, feature in enumerate(X.columns):\n            plt.subplot(3, 3, i+1)\n            \n            # Generate synthetic data with proper values\n            if feature in numerical_features:\n                values = np.linspace(X[feature].quantile(0.05), \n                         X[feature].quantile(0.95), 100)\n            else:\n                values = X[feature].unique()\n            \n            # Create base values for other features\n            base_values = {\n                col: X[col].median() if col in numerical_features \n                else X[col].mode()[0] \n                for col in X.columns\n            }\n            \n            # Create synthetic dataframe\n            synthetic = pd.DataFrame([base_values] * len(values))\n            synthetic[feature] = values\n            \n            # Predict and plot\n            preds = model.predict(synthetic)\n            sns.lineplot(x=values, y=preds, color='red', label='Partial Dependence')\n            sns.scatterplot(x=X[feature], y=y, alpha=0.1, label='Actual Data')\n            plt.title(f\"Partial Dependence: {feature}\")\n            plt.legend()\n            \n        plt.tight_layout()\n        plt.show()\n        \ndef generate_submission(model, test_data, output_path, sample_submission_path):\n    predictions = model.predict(test_data).round(2)\n    sample_sub = pd.read_csv(sample_submission_path)\n    submission = sample_sub[['row_id']].assign(Y=predictions)\n    submission.to_csv(output_path, index=False)\n    print(f\"Submission saved to {output_path}\")\n\nif __name__ == \"__main__\":\n    # Path configurations\n    train_path = \"/kaggle/input/app-rating-competition/train.csv\"\n    test_path = \"/kaggle/input/app-rating-competition/test.csv\"\n    sample_path = \"/kaggle/input/app-rating-competition/SampleSubmission.csv\"\n    output_path = \"/kaggle/working/submission.csv\"\n\n    # Preprocess data\n    train_data, imputers, feature_cols = preprocess_train_data(train_path)\n\n    X = train_data.drop('Y', axis=1)\n    y = train_data['Y']\n\n    # Train model\n    model = train_on_full_data(X, y)\n    \n    # Analyze features\n    analyze_features(X, y, model=model)\n\n    # Prepare test data\n    test_data, test_ids = preprocess_test_data(test_path, imputers, feature_cols)\n    \n    # Generate submission\n    generate_submission(model, test_data, output_path, sample_path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-09T23:25:41.229004Z","iopub.execute_input":"2025-05-09T23:25:41.229458Z","iopub.status.idle":"2025-05-09T23:25:44.452274Z","shell.execute_reply.started":"2025-05-09T23:25:41.229425Z","shell.execute_reply":"2025-05-09T23:25:44.451275Z"}},"outputs":[],"execution_count":null}]}